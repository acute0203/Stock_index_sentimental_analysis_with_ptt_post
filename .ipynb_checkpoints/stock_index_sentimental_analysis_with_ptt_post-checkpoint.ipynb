{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Utils():\n",
    "    \n",
    "    def write_json_to_file(json_data, json_file_path):\n",
    "        with open(json_file_path, 'w') as out_file:\n",
    "            json.dump(json_data, out_file)\n",
    "        return 1\n",
    "\n",
    "    def read_json_from_file(json_file_path):\n",
    "        with open(json_file_path) as data_file:  \n",
    "            data = json.load(data_file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,time\n",
    "import os.path\n",
    "import jieba,re\n",
    "import datetime\n",
    "import hashlib\n",
    "from libs.Crawler_and_Share.load_data_from_mysql import load_data_from_mysql\n",
    "\n",
    "class PostData():\n",
    "    def __init__(self):\n",
    "        self.post_data = load_data_from_mysql(data_name = 'Stock')\n",
    "        print(\"Get data from DB done\")\n",
    "        \n",
    "    def get_emotion_dict(self, path = \"chinese-corpus/emotion-dic/taiwan/\", dict_list = ['NTUSD_positive_simplified.txt','NTUSD_negative_simplified.txt']):\n",
    "        #load emotion dict\n",
    "        def get_emotion_dict_from_file(path, emotion_score): \n",
    "            emotion_dict = {} \n",
    "            with open(path, 'r') as f: \n",
    "                for line in f: \n",
    "                    key = line.strip()\n",
    "                    emotion_dict[key] = int(emotion_score) \n",
    "            return emotion_dict\n",
    "    \n",
    "        emotion_dict = {}\n",
    "        for dl in dict_list:\n",
    "            #using file name to check the file is positive dictionary or negative dictionary\n",
    "            emo_score = 1 if 'positive' in dl.lower() else -1\n",
    "            #combine with exist emotion dictionary\n",
    "            emotion_dict={**emotion_dict, **get_emotion_dict_from_file(path + dl, emo_score)}\n",
    "        return emotion_dict\n",
    "    \n",
    "    def calc_emotion_score(self, seg_list, emotion_dict):\n",
    "        news_positive_score=0\n",
    "        news_negative_score=0\n",
    "        for word in seg_list:\n",
    "            if word in emotion_dict:\n",
    "                if emotion_dict[word] < 0:\n",
    "                    news_negative_score += abs(emotion_dict[word])\n",
    "                else:\n",
    "                    news_positive_score += emotion_dict[word]\n",
    "        return news_positive_score, news_negative_score\n",
    "\n",
    "    def custom_clean_article(self ,article):\n",
    "        article = re.sub('[\\d]', '', article)\n",
    "        article = re.sub('[\\n]', '', article)\n",
    "        return article\n",
    "    \n",
    "    def seg_article(self, article):\n",
    "        return list(filter(None, jieba.cut(article, cut_all=True)))\n",
    "    \n",
    "    def make_post_data(self, json_file_path = \"newsJSONData.json\"):\n",
    "        json_data = {\"parsedMD5\":[], \"dayScore\":{}, \"startDate\": time.strftime(\"%Y-%m-%d\")}\n",
    "        for post in self.post_data.iterrows():\n",
    "            #calculate MD5 of article\n",
    "            article_MD5 = hashlib.md5(post[1]['clean_article'].encode('utf-8')).hexdigest()\n",
    "            #if the article have been parsed before, there's no need to parse again\n",
    "            if article_MD5 not in json_data[\"parsedMD5\"]:\n",
    "                #get the date of the article\n",
    "                article_date = post[1]['date']\n",
    "                #change the date to regular format, EX:date format:2007-07-24 13:10:49 to 2007-07-24\n",
    "                article_date_format = datetime.datetime.strptime(article_date, '%Y-%m-%d %H:%M:%S').strftime(\"%Y-%m-%d\")\n",
    "                #if the date is before 1911-01-01 ,means incorrect date\n",
    "                if article_date_format < datetime.datetime.strptime('1911-01-01', '%Y-%m-%d').strftime(\"%Y-%m-%d\"):\n",
    "                    continue\n",
    "                #update the oldest date\n",
    "                if article_date_format < json_data[\"startDate\"]:\n",
    "                    json_data[\"startDate\"] = article_date_format\n",
    "                article_date = str(article_date_format)\n",
    "                #if json do not contains the day's score, initialize day score\n",
    "                if article_date not in json_data[\"dayScore\"]:\n",
    "                    json_data[\"dayScore\"][article_date] = [0, 0]\n",
    "                #use the value of clean_article as article\n",
    "                article = post[1]['clean_article']\n",
    "                #using custom cleaner to clean the data \n",
    "                article = self.custom_clean_article(article)\n",
    "                #segment the article\n",
    "                seg_list = self.seg_article(article)\n",
    "                #get emotion dictionary\n",
    "                emotion_dict = self.get_emotion_dict()\n",
    "                #calculate the emotion score\n",
    "                news_positive_score, news_negative_score = self.calc_emotion_score(seg_list, emotion_dict)\n",
    "                #add positive score\n",
    "                json_data[\"dayScore\"][article_date][0] += news_positive_score\n",
    "                #add negative score\n",
    "                json_data[\"dayScore\"][article_date][1] += news_negative_score\n",
    "                #add MD5 to list for record the document have been parsed before \n",
    "                json_data[\"parsedMD5\"].append(article_MD5)\n",
    "        #write to json file\n",
    "        Utils.write_json_to_file(json_data, json_file_path)\n",
    "        print(\"The file have been made at \" + json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self,training_data, training_labels):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, predict_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class GaussianNaiveBayesClassification(ClassificationModel):\n",
    "    def __init__(self):\n",
    "        self.model = GaussianNB()\n",
    "        \n",
    "    def train(self,training_data, training_labels):\n",
    "        self.model.fit(training_data, training_labels)\n",
    "    \n",
    "    def predict(self, predict_data):\n",
    "        return self.model.predict(predict_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web \n",
    "\n",
    "class PriceData():\n",
    "    \n",
    "    def __init__(self, start, end, company = \"TSM\", source = 'google'):\n",
    "        #fetch data from google \n",
    "        self.f = web.DataReader(company, source, start, end) \n",
    "        dates = self._change_date_format()\n",
    "        self.date_per_change = self._calc_date_price_percentage(dates)\n",
    "        \n",
    "    def _change_date_format(self):\n",
    "        #check date format\n",
    "        dates =[]\n",
    "        for x in range(len(self.f)): \n",
    "            newdate = str(self.f.index[x]) \n",
    "            newdate = newdate[0:10] \n",
    "            dates.append(newdate) \n",
    "        return dates\n",
    "    \n",
    "    def _calc_date_price_percentage(self, dates):\n",
    "        #store date(key) and change percentage(value) into dictonary \n",
    "        date_price_percentage={} \n",
    "        #change to percentage \n",
    "        last_day_index = 0 \n",
    "        for date in dates: \n",
    "            current_day_index = self.f.loc[date]['Close'] \n",
    "            current_day_date=date \n",
    "            if dates.index(current_day_date)!=0: \n",
    "                #change to percentage \n",
    "                #if it's the very first day, there's no index to compare so just pass it \n",
    "                current_day_change_percentage=(current_day_index-last_day_index)*100 / last_day_index if last_day_index !=0 else 0 \n",
    "                #put into dictionary \n",
    "                date_price_percentage[current_day_date] = current_day_change_percentage \n",
    "            last_day_index = current_day_index\n",
    "        return date_price_percentage\n",
    "    \n",
    "    def get_price_data(self):\n",
    "        return self.date_per_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import os,json,time\n",
    "import datetime as dt\n",
    "import os.path\n",
    "\n",
    "def normalize_emotion_score(emotion_score_list):\n",
    "    total_score=sum(emotion_score_list) + 1\n",
    "    return [float(score) / total_score for score in emotion_score_list]\n",
    "\n",
    "def pare_training_data(date_price, date_article_score):\n",
    "    training_index=[]\n",
    "    training_emotion=[]\n",
    "    for date in date_article_score:\n",
    "        date_format=datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        #add one day\n",
    "        next_day=str((date_format + timedelta(days = 1)).strftime(\"%Y-%m-%d\"))\n",
    "        if (next_day in date_price) and (normalize_emotion_score(date_article_score[date])!=0):\n",
    "            training_index.append([date_price[next_day]])\n",
    "            training_emotion.append(normalize_emotion_score(date_article_score[date]))\n",
    "    return training_index,training_emotion\n",
    "\n",
    "#clustering the stock price with n cluster, where n is cluster number\n",
    "def price_clustering(training_index, n = 10):\n",
    "    X = np.array(training_index)\n",
    "    kmeans = KMeans(n_clusters=n, random_state=0).fit(X)\n",
    "    clustering_result = kmeans.labels_\n",
    "    clustering_center = kmeans.cluster_centers_\n",
    "    return np.array(clustering_result), clustering_center\n",
    "\n",
    "def main():\n",
    "    #read date score from json\n",
    "    json_file_path = \"newsJSONData.json\"\n",
    "    #if the file does not exist, then it will load the data from database, which was provided by\n",
    "    #https://github.com/jwlin/ptt-web-crawler\n",
    "    if not os.path.exists(json_file_path):\n",
    "        pdata = PostData()\n",
    "        pdata.make_post_data(json_file_path)\n",
    "    json_data = Utils.read_json_from_file(json_file_path)\n",
    "    #initial date we need to fetch \n",
    "    start_date = json_data['startDate']\n",
    "    date_article_score = json_data['dayScore']\n",
    "    #EX : date_article_score={\"2016-12-05\":[4,3],\"2016-12-06\":[1,1],\"2016-12-07\":[3,10],\"2016-12-08\":[3,9]}\n",
    "    #set end date at 2018-02-07\n",
    "    end_date = datetime.strptime('2018-02-07', '%Y-%m-%d').strftime(\"%Y-%m-%d\")\n",
    "    print(\"Article start date:\" + str(start_date))\n",
    "    print(\"Set up analyze end date:\" + str(end_date))\n",
    "    #init data\n",
    "    data = PriceData(start_date, end_date, company = \"TSM\",source = 'google')\n",
    "    #get date price \n",
    "    date_price = data.get_price_data()\n",
    "    #combine date price and date score\n",
    "    training_index, training_emotion = pare_training_data(date_price, date_article_score)\n",
    "    #clustering the price into n group, where n by default is set to 10. \n",
    "    #it will retuurn the clustering result of each data and the center of each group\n",
    "    clustering_result, clustering_center= price_clustering(training_index, n = 10)\n",
    "\n",
    "    #classification\n",
    "    #initialize\n",
    "    cm = GaussianNaiveBayesClassification()\n",
    "    #Using clustering result to train classification model.\n",
    "    cm.train(training_emotion, clustering_result)\n",
    "\n",
    "    #using the end date to test it can work or not\n",
    "    end_date = str(end_date)\n",
    "    if end_date in date_article_score and (normalize_emotion_score(date_article_score[end_date])!=0):\n",
    "        today_emotion_score = normalize_emotion_score(date_article_score[end_date])\n",
    "        #working correct\n",
    "        print(\"Index close price might close to \"+str(clustering_center[cm.predict(np.array([today_emotion_score]))]))\n",
    "    else:\n",
    "        #working wrong\n",
    "        print(\"Something Wrong...\")\n",
    "        print(date_article_score)\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
